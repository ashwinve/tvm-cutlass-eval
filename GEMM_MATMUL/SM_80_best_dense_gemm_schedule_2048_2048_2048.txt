#[version = "0.0.5"]
def @main(%data: Tensor[(2048, 2048), float32], %weight: Tensor[(2048, 2048), float32]) -> Tensor[(2048, 2048), float32] {
  @tvmgen_default_cutlass_main_0(%data, %weight) /* ty=Tensor[(2048, 2048), float32] */
}

def @tvmgen_default_cutlass_main_0(%cutlass_0_i0: Tensor[(2048, 2048), float32], %cutlass_0_i1: Tensor[(2048, 2048), float32], Inline=1, arg1_shape=[2048, 2048], op_type="cutlass.dense", arg0_dtype="float32", Compiler="cutlass", ret_dtype="float32", ldb="K", global_symbol="tvmgen_default_cutlass_main_0", lda="K", Primitive=1, cutlass_op_name="cutlass_tensorop_s1688gemm_128x128_16x3_tn_align4", ldc="N", cutlass_op_def="
  // Gemm operator cutlass_tensorop_s1688gemm_128x128_16x3_tn_align4
  using Operation_cutlass_tensorop_s1688gemm_128x128_16x3_tn_align4 = cutlass::gemm::device::Gemm<
    float, cutlass::layout::RowMajor,
    float, cutlass::layout::ColumnMajor,
    float, cutlass::layout::RowMajor,
    float,
    cutlass::arch::OpClassTensorOp,
    cutlass::arch::Sm80,
    cutlass::gemm::GemmShape<128, 128, 16>,
    cutlass::gemm::GemmShape<32, 64, 16>,
    cutlass::gemm::GemmShape<16, 8, 8>,
    
    cutlass::epilogue::thread::LinearCombination<
      float,
      4,
      float,
      float
    >,
    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
    3,
    4,
    4,
    false,
    cutlass::arch::OpMultiplyAddFastF32
  >;
", ret_shape=[2048, 2048], arg1_dtype="float32", arg0_shape=[2048, 2048]) -> Tensor[(2048, 2048), float32] {
  %0 = fn (%FunctionVar_0_0: Tensor[(2048, 2048), float32], %FunctionVar_0_1: Tensor[(2048, 2048), float32], PartitionedFromPattern="nn.dense_", Composite="cutlass.dense") -> Tensor[(2048, 2048), float32] {
    nn.dense(%FunctionVar_0_0, %FunctionVar_0_1, units=None, out_dtype="float32") /* ty=Tensor[(2048, 2048), float32] */
  };
  %0(%cutlass_0_i0, %cutlass_0_i1) /* ty=Tensor[(2048, 2048), float32] */
}
